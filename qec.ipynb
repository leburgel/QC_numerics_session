{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating quantum error correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Introduction](#intro)\n",
    "    - [Stabilizer quantum error correcting codes](#stabilizer)\n",
    "    - [Error correction in stabilizer codes](#decoding)\n",
    "- [Simulating stabilizer error correction](#stabilizer_simulation)\n",
    "    - [The qecsim software package](#qecsim)\n",
    "    - [The stim software package](#stim)\n",
    "- [Example: error correction in the toric code](#example1)\n",
    "    - [Toric code stabilizers and logicals](#tc)\n",
    "    - [Errors and corrections](#tc_qec)\n",
    "    - [The toric code error correction threshold](#tc_threshold)\n",
    "- [Example: adding circuit and measurement noise](#example2)\n",
    "    - [Implementing error correcting codes](#circuits)\n",
    "    - [Adding gate and measurement noise](#noise)\n",
    "    - [Fault-tolerant threshold](#fault_tolerant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stabilizer quantum error correcting codes <a id='stabilizer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the definition of a stabilizer quantum error correcting code from the lectures. A stabilizer code is defined by an Abelian subgroup $\\mathcal{S}$ of the $n$-qubit Puli group, whose joint $+1$-eigenspace gives the codespace. We usually specify $\\mathcal{S}$ in terms of a set of generators\n",
    "$$\\{g_1,g_2\\ldots g_t\\}$$\n",
    "such that any other operator in $\\mathcal{S}$ can be written as a product of the $g_i$'s.\n",
    "\n",
    "The logical operators of a stabilizer code are operators that act within the code space, meaning they must map stabilizers to stabilizers under conjugation. In particular, logical Pauli operators are Pauli operators that commute with all elements of $\\mathcal{S}$. Logical Pauli operators are not unique, but are only defined up to multiplication by elements of $\\mathcal{S}$. If $P$ is a logical Pauli operator, then $Ps = sP$ is also a logical operator with the same action on the code spae, for all $s \\in \\mathcal{S}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error correction in stabilizer codes <a id='decoding'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error correction in stabilizer codes is performed by repeatedly measuring a complete set of stabilizer generators. When an error occurs on the code space, any stabilizer whose eigenvalue is not measured to be $+1$ is said to belong to the syndrome of that error. Based on that syndrome, a decoding algorithms then decides on a suitable correction operator to be applied that brings the system back to the code space, and, hopefully, should cancel the error. If the product of this correction and the original error lies in the stabilizer group, then the total action is trivial and error correction is successful. If the product is not in the stabilizer group, then a logical error has occurred, and error correction has failed.\n",
    "\n",
    "For our discussion we will restrict to Pauli errors $E$, which by definition can only commute or anticommute with the stabilizer generators. The syndrome of a Pauli errors is then given by the generators that anticommute with the error. Based on the syndrome the decoder proposes a recovery $E$ such that $ER$ commutes with the stabilizer, in the hope that this product actually lies in the stabilizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating stabilizer error correction <a id='stabilizer_simulation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist many packages that provide tools for simulating quantum error correction. Here we will focus on just two of them, which are particularly suitable for pedagogical purposes. Each of these packages tackles the problem of error correction from a slightly different angle. We will start by considering stabilizer error correction in a more 'traditional' sense, focusing on stabilizers and logical operators. Next, we will consider a more 'circuit-based' approach, where the central focus lies on the quantum circuits that actually implement the stabilizer measurements, and how to sample these circuits under different conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The [qecsim](https://qecsim.github.io/index.html) software package <a id='qecsim'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first package we will use is qecsim.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>From the qecsim documentation:</b> <i>qecsim is a Python 3 package for simulating quantum error correction using stabilizer codes. It is lightweight, modular and extensible, allowing additional codes, error models and decoders to be plugged in.</i> </div>\n",
    "\n",
    "An honourable mention for a package with similar functionalities goes to [PanQEC](https://panqec.readthedocs.io/en/latest/index.html). This latter package has some more builtin codes and decoders and is therefore very suitable for exploring stabilizer error correction. However, the simple ASCII visualizations exported by qecsim give it an edge for our current purpose. In that spirit, you are alsoencouraged to play around with the [exellent quantum code visualizer found here](https://gui.quantumcodes.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### The [Stim](https://github.com/quantumlib/Stim/tree/main) software package <a id='stim'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next package we will use is Stim.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>From the Stim README:</b> <i>Stim is a tool for high performance simulation and analysis of quantum stabilizer circuits, especially quantum error correction (QEC) circuits.</i> </div>\n",
    "\n",
    "Stim is a very powerful tool for analyzing and sampling stabilizer circuits under noise models of varying complexity. However, it does not directly contain decoders to decode the stabilizer measurement samples. A decoder that works particularly well in conjunction with Stim is [PyMatching](https://pymatching.readthedocs.io/en/stable/#), which is a very flexible Python implementation of a minimum-weight perfect matching decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: error correction in the toric code <a id='example1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first example, we will consider 'conventional' stabilizer error correction in the toric code under bit-flip noise using qecsim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qecsim.models.toric import ToricCode\n",
    "from qecsim_wrappers import print_code, print_pauli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toric code stabilizers and logicals <a id='tc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the toric code is a stabilizer code defined on a 2D square lattice with periodic boundary conditions, where a qubit is placed on each edge of the lattice. We will assume the lattice is of size $L\\times L$, so there are $n=2L^2$ qubits.\n",
    "\n",
    "The toric code stabilizer generators are given by the star and plaquette operators $ A_s $ and $ B_p $, defined as\n",
    "$$A_s = \\prod_{j \\in s} Z_j\\,, \\qquad B_p = \\prod_{j \\in p} X_j\\,,$$\n",
    "where $ j \\in s $ and $ j \\in p $ denote all the edges $ j $ incident to the vertex $ s $, and bounding the plaquette $ p $ respectively.\n",
    "The stabilizer group of the toric code is then\n",
    "$$\\mathcal{S} = \\{ A_s, B_p \\mid s \\text{ is a vertex of the lattice},\\, p \\text{ is a plaquette of the lattice} \\}.$$\n",
    "The logical operators are given by non-contractible loops of $X$ and $Z$ operators on the lattice and dual lattice respectively.\n",
    "\n",
    "qecsim implements the toric code as a specific subtype of a `StabilizerCode`, `ToricCode`. As a first step, we can construct a toric code object for a given lattice size and inspect its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 8 # linear lattice size\n",
    "p = 0.05 # error probability\n",
    "\n",
    "code = ToricCode(L, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the code parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.n_k_d # [[2L^2, 2, L]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the code layout to check the geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_code(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print some stabilizer generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(code.stabilizers) # 2 L^2 stabilizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pauli(code, code.stabilizers[14]) # a random plaquette stabilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pauli(code, code.stabilizers[90]) # a random vertex stabilizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can print the pairs of logical operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(code.logicals) # 4 logical operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first pair of logical paulis\n",
    "print_pauli(code, code.logicals[0]) # first logical Z\n",
    "print_pauli(code, code.logicals[2]) # first logical X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the second pair of logical paulis\n",
    "print_pauli(code, code.logicals[1]) # second logical Z\n",
    "print_pauli(code, code.logicals[3]) # second logical X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors and corrections <a id='tc_qec'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can have a look at errors, syndromes, decoders, correction operators, and (potential) logical errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qecsim.models.toric import ToricMWPMDecoder\n",
    "from qecsim_wrappers import bit_flip_model, compute_syndrome, print_syndrome, pauli_product, logical_commutations, effective_logical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple bit-flip error model, which is an instance of a a subtype of [`qecsim.model.ErrorModel`](https://qecsim.github.io/api/model.html#qecsim.model.ErrorModel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_model = bit_flip_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a random error model and a code, we can generate a random error by calling the [`generate` method](https://qecsim.github.io/api/model.html#qecsim.model.ErrorModel.generate) method by supplying it with the code and a physical error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.05 # physical error probability per qubit\n",
    "E = error_model.generate(code, p)\n",
    "print_pauli(code, E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have an error we can evaluate its syndrome using `compute_syndrome`. This returns a binary vector indicating the stabilizer that anticommute with the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome = compute_syndrome(code, E)\n",
    "syndrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print this syndrome which shows that it, of course, only consists only of $Z$-type vertex stabilizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_syndrome(code, syndrome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qecsim also provides a minimum-weight perfect matching decoder for the toric code, `ToricMWPMDecoder`, which we can use to correct our random error error. After initializing the decoder, we can pass the code and the error syndrom to its [][`decode` method](https://qecsim.github.io/api/model.html#qecsim.model.Decoder.decode) method to obtain a correction Pauli operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = ToricMWPMDecoder() # initializer MWPM decoder for the toric code\n",
    "R = decoder.decode(code, syndrome)\n",
    "print_pauli(code, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For low noise rates, it is easy to see that the correction operator pairs up neighboring vertex syndromes with strings of $Z$ errors. This is precisely what we expect from a matching decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the product of the error and the correction operator using [`pauli_prodcut`], we can visualize its combined action. For low noise rates, this will usually be trivial or clearly correspond to a stabilizer, indication successful error correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ER = pauli_product(E, R)\n",
    "print_pauli(code, ER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that it is indeed trivial, we can check if the total action $ER$ anticommutes with any of the logcical operators using the `logical_commutations` function. If it commutes with all logicals it is a logical identity and correction is successful. If it instead anticommutes with any of the logicals it is a logical operator itself, and correction fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anticommutations = logical_commutations(code, ER)\n",
    "anticommutations # returns a binary vector indicating which of the logicals the operator anticommutes with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a convenience tool, we can use the function `effective_logical` to find the logical operator that corresponds to the total action of the error and correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_log, eff_label = effective_logical(code, ER)\n",
    "print(f\"Effective logical operator after error and recovery:\\t{eff_label}\")\n",
    "print_pauli(code, eff_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try playing around with the physical error rate to see how the decoder performs at different noise levels. You will find more and more logical errors as the noise rate increases. Intuitively, you should be able to see how pairing up syndromes that are close to each other does not always work in these regimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explicitly show the limitations of the matching decoder, we can have a look at two errors with the same syndrome, one of which is correctable and the other is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qecsim_wrappers import good_E, bad_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pauli(code, good_E) # weight-3 error, where 3 < d/2, so correctable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_s = compute_syndrome(code, good_E)\n",
    "print_syndrome(code, good_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successfull_R = decoder.decode(code, good_s)\n",
    "print_pauli(code, successfull_R) # recover is the same as the original error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_log, eff_label = effective_logical(code, pauli_product(good_E, successfull_R))\n",
    "print(f\"Effective logical operator after error and recovery:\\t{eff_label}\")\n",
    "print_pauli(code, eff_log) # total effect is trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pauli(code, bad_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_s = compute_syndrome(code, bad_E)\n",
    "print_syndrome(code, bad_s) # same syndrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsuccessfull_R = decoder.decode(code, bad_s)\n",
    "print_pauli(code, unsuccessfull_R) # but the recovery is now different from the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_log, eff_label = effective_logical(code, pauli_product(bad_E, unsuccessfull_R))\n",
    "print(f\"Effective logical operator after error and recovery:\\t{eff_label}\")\n",
    "print_pauli(code, eff_log) # and their total action is a logical X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The toric code error correction threshold <a id='tc_threshold'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qecsim import app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tools we have demonstrated so far are all we need to estimate the error correction threshold of the toric code. To do this, we simply need to run the error correction procedure outlined above many times and compute the logical failure rate as the total number of logical errors divided by the number of runs, and this for several values of the physical error rate and code size. We then hope to find a critical value $p_{\\text{th}}$ of the physical error rate below which the logical failure rate goes to zero in the limit of large code size.\n",
    "\n",
    "We will perform this analysis using the convenient [application functions in the qecsim `app` module](https://qecsim.github.io/api/app.html#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize run parameters\n",
    "\n",
    "# set models\n",
    "codes = [ToricCode(*size) for size in [(3, 3), (5, 5), (7, 7), (9, 9)]]\n",
    "error_model = bit_flip_model()\n",
    "decoder = ToricMWPMDecoder()\n",
    "# set physical error probabilities\n",
    "error_probability_min, error_probability_max = 0.06, 0.14\n",
    "error_probabilities = np.linspace(error_probability_min, error_probability_max, 5)\n",
    "# set max_runs for each probability\n",
    "max_runs = 1000\n",
    "\n",
    "# print run parameters\n",
    "print('Codes:', [code.label for code in codes])\n",
    "print('Error probabilities:', error_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run simulations and print data from middle run to view format; this might take a while\n",
    "data = [app.run(code, error_model, decoder, error_probability, max_runs=max_runs)\n",
    "        for code in codes for error_probability in error_probabilities]\n",
    "print(data[len(data)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for plotting\n",
    "code_to_xys = {}\n",
    "for run in data:\n",
    "    xys = code_to_xys.setdefault(run['code'], [])\n",
    "    xys.append((run['physical_error_rate'], run['logical_failure_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the simulated data\n",
    "fig = plt.figure(1, figsize=(8, 5))\n",
    "plt.title('Toric code simulation\\n(Bit-flip noise, {} decoder)'.format(decoder.label))\n",
    "plt.xlabel('Physical error rate')\n",
    "plt.ylabel('Logical failure rate')\n",
    "plt.xlim(error_probability_min-0.01, error_probability_max+0.01)\n",
    "plt.ylim(-0.05, 0.7)\n",
    "# add data\n",
    "for code, xys in code_to_xys.items():\n",
    "    plt.plot(*zip(*xys), 'x-', label='{} code'.format(code))\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some simulation time, we find a threshold of about $p_{\\text{th}} \\approx 10\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: adding circuit and measurement noise <a id='example2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing error correcting codes <a id='circuits'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When putting error correction into practice on a physical device, we need a way of actually measuring the stabilizer generators. As we have seen in the exercise sessions, this can be done by introducing an ancilla qubit for each stabilizer generator, entangling these ancilla in a suitable way with the qubits their corresponding stabilizer acts on, and then measuring the ancilla qubits in the computateional basis.\n",
    "\n",
    "Indeed, we have already seen some examples of these so-called *syndrome extraction circuits*. A $Z^{\\otimes 4}$ stabilizer can be measured using the $Z$-parity circuit\n",
    "\n",
    "<center><img src=\"./fig/z_stabilizer_circuit.svg\" alt=\"z_stabilizer\"/></center>\n",
    "\n",
    "while an $X^{\\otimes 4}$ stabilizer can be measured using the $X$-parity circuit\n",
    "\n",
    "<center><img src=\"./fig/x_stabilizer_circuit.svg\" alt=\"x_stabilizer\"/></center>\n",
    "\n",
    "However, once we acknowledge the fact that we constantly have to execute these kinds of syndrome extraction circuits and add to this the fact that any component and operation in an actual quantum device is noisy, it becomes clear that we should take into account the noise that occurs during the syndrome extraction process when simulating error correction.\n",
    "\n",
    "To this end we will have a look at the [Stim software package](https://github.com/quantumlib/Stim/tree/main), which allows us to define error correcting codes directly from the circuits that are used to implement them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by looking at an example, namely the so-called rotated surface code, which you can think of as a version of the toric code implemented on a finite plane with open boundary conditions. The circuit that implements 4 rounds of syndrome measurements in a distance-3 surface code can be loaded as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = stim.Circuit.generated(\n",
    "    \"surface_code:rotated_memory_z\",\n",
    "    rounds=4,\n",
    "    distance=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we print it, we see it consists of a sequence of instructions written in Stim's own internal format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can visualize the circuit on a time-line to get a clear picture of what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit.diagram('timeline-svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immedialy see that the circuit implements a sequence of $X$ and $Z$ stabilizer measurements very similar to those of the toric code. We also note that it uses the measurement outcomes to define so-called 'detectors'. A detector is nothing more than a collection of measurement results that should sum to zero modulo 2. Here, the detectors simply encode that, in the absence of errors, the stabilizer measurements in any two consecutive rounds of syndrome extraction should have the same outcome.\n",
    "\n",
    "Another nice way of visualizing the flow of entangling gates and ancilla measurements is to plot time slices of the circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit.diagram('timeslice-svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding gate and measurement noise <a id='noise'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The circuit we have just looked at is annotated with detectors, which detect whether stabilizer measurements between different rounds have the same outcome. Of course in an ideal world this would always be the case, but in reality noise can flip some of these outcomes, triggering certain detectors.\n",
    "\n",
    "Moreover, in contrast to the simple bit-flip noise we have considered so far, noise in real devices is not limited to flipping qubits. Instead, we have to deal with noise that can occur at any point in the circuit, and that can be of many different types. For example, a gate might not be executed correctly, a measurement might be faulty, an ancilla reset may fail, and so on.\n",
    "\n",
    "All these different kinds of noise pocesses can be added to a circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = stim.Circuit.generated(\n",
    "    \"surface_code:rotated_memory_z\",\n",
    "    rounds=4,\n",
    "    distance=3,\n",
    "    after_clifford_depolarization=0.001, # gate-level noise\n",
    "    after_reset_flip_probability=0.001, # ancilla reset noise\n",
    "    before_measure_flip_probability=0.001, # measurement noise\n",
    "    before_round_data_depolarization=0.001, # data qubit noise\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit.diagram('timeline-svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit.diagram('timeslice-svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without going into the specifics of all these error processes, it is immediately clear that figuring out the effect of all these noise processes on the stabilizer measurements is a non-trivial task. This is where Stim comes in. Stim allows us to sample the output of a noisy stabilizer circuit, and to analyze the effect of noise on the stabilizer measurements. Just as before, these stabilizer measurements can then be fed into a decoder to correct the errors.\n",
    "\n",
    "However, whereas before we had a very clear intuitive picture of matching as pairing up syndromes laid out on a 2D grid, the problem of matching syndromes in a repeated execution of a noisy circuit is quite a different thing. This can already be seen by just looking at the matching graph corresponding to the planar code error correction circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit.diagram(\"matchgraph-3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this 3D matching problem seems quite a bit more involved than the case we considered previously, the principle remains exactly the same. In particular, our matching decoder will suggest a correction operation, after which we can check if the product of the error and the correction operator corresponds to a non-trivial logical operator or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fault-tolerant threshold <a id='fault_tolerant'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sinter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given all these additional error processes that can occur in the circuit picture, we can ask how this affects the error correction threshold.\n",
    "\n",
    "We can do this by repeating exactly the kind of simulation we did before, but now for the surface code under circuit noise. Here, we will take the noise rates for all the error processes to be equal, and we will vary this global noise rate to see how the logical failure rate for different code sizes. Again, we hope to find a critical value $p_{\\text{th}}$ of the physical error rate below which the logical failure rate goes to zero in the limit of large code size. This threshold would be called 'fault-tolerant', since it persists in the setting where all aspects of the error correction procedure are noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will perform the simulation according to the functionality provided by the [`sinter` sampling module](https://github.com/quantumlib/Stim/tree/main/glue/sample) built on top of Stim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_code_tasks = [\n",
    "    sinter.Task(\n",
    "        circuit = stim.Circuit.generated(\n",
    "            \"surface_code:rotated_memory_z\",\n",
    "            rounds=d * 3,\n",
    "            distance=d,\n",
    "            after_clifford_depolarization=noise,\n",
    "            after_reset_flip_probability=noise,\n",
    "            before_measure_flip_probability=noise,\n",
    "            before_round_data_depolarization=noise,\n",
    "        ),\n",
    "        json_metadata={'d': d, 'r': d * 3, 'p': noise},\n",
    "    )\n",
    "    for d in [3, 5, 7]\n",
    "    for noise in [0.008, 0.009, 0.01, 0.011, 0.012]\n",
    "]\n",
    "\n",
    "collected_surface_code_stats = sinter.collect(\n",
    "    num_workers=4,\n",
    "    tasks=surface_code_tasks,\n",
    "    decoders=['pymatching'],\n",
    "    max_shots=5_000_000,\n",
    "    max_errors=10_000,\n",
    "    print_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "sinter.plot_error_rate(\n",
    "    ax=ax,\n",
    "    stats=collected_surface_code_stats,\n",
    "    x_func=lambda stat: stat.json_metadata['p'],\n",
    "    group_func=lambda stat: stat.json_metadata['d'],\n",
    "    failure_units_per_shot_func=lambda stat: stat.json_metadata['r'],\n",
    ")\n",
    "ax.set_ylim(5e-3, 5e-2)\n",
    "ax.set_xlim(0.008, 0.012)\n",
    "ax.loglog()\n",
    "ax.set_title(\"Surface code simulation\\n(Circuit noise, MWPM decoder\")\n",
    "ax.set_xlabel(\"Phyical error rate\")\n",
    "ax.set_ylabel(\"Logical failure rate per round\")\n",
    "ax.grid(which='major')\n",
    "ax.grid(which='minor')\n",
    "ax.legend()\n",
    "fig.set_dpi(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can see that we find a fault-tolerant threshold of about $p_{\\text{th}} \\approx 1\\%$. This means taking into account noise in the error correction circuits reduced the threshold by an order of magnitude. This, again, shows that dealing with errors in a realistic setting is a very difficult problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
